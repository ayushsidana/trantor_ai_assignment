# trantor_ai_assignment

My Chat API
This is a FastAPI-based API server that accepts a question as input and returns an answer generated by OpenAI's chat completion. The application also supports logging requests to a database, and implements backoff for OpenAI calls and a job queue using Celery.

Prerequisites
Python 3.8 or higher
Poetry for package management
Redis (for Celery, optional)

Installation
cd trantor-ai-assignment
poetry install
poetry shell  - used to activate the virtual env created

Create a .env file in the root directory with the environment variables mentioned in .env.example file

poetry shell - use this command to activate the virtual environment

Configuration
FastAPI Configuration: FastAPI runs on the Uvicorn ASGI server. You can configure host, port, workers, etc., in main.py.
Database Configuration: The database is managed using SQLModel. Update the DATABASE_URL in .env for your specific database setup.
Celery Configuration: Celery is configured to use Redis as the message broker and result backend. Modify CELERY_BROKER_URL and CELERY_RESULT_BACKEND in .env as needed.

Run the FastAPI application:
poetry run uvicorn app.main:app --reload

Access the API documentation at http://localhost:8000/docs to test the endpoints.

Testing
To run your Mamba tests, use the following command:
poetry run pytest

Contributing
Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.